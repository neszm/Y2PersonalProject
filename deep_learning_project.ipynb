{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e95f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771537e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4366c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0], cmap=\"gray\") # cmap=\"gray\" to make it balck & white\n",
    "plt.title(f\"Label: {y_train[0]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 12\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    plt.imshow(x_train[i], cmap=\"gray\")\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aecec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "!pip install numpy\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(class_distribution.keys()), y=list(class_distribution.values()))\n",
    "plt.title(\"Class Distribution in MNIST Dataset\")\n",
    "plt.xlabel(\"Digits\")\n",
    "plt.ylabel(\"Num of Samples\")\n",
    "plt.xticks(rotation=0) # force them to be horizontal\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f26173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to [0,1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "base_model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "#base_model.fit(x_train, y_train, epochs=5)\n",
    "base_history = base_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_history.history.keys())\n",
    "\n",
    "plt.plot(base_history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "if \"val_accuracy\" in base_history.history:\n",
    "    plt.plot(base_history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy Over Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79681b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel = keras.Sequential([\n",
    "    keras.layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bdbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to [0,1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "CNNmodel.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "#CNNmodel.fit(x_train, y_train, epochs=5)\n",
    "CNN_history = CNNmodel.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(CNN_history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "if \"val_accuracy\" in CNN_history.history:\n",
    "    plt.plot(CNN_history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy Over Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb13b7e",
   "metadata": {},
   "source": [
    "what if we run them for longer does that help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_history_lt = base_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=15,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696195f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(base_history_lt.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "if \"val_accuracy\" in base_history_lt.history:\n",
    "    plt.plot(base_history_lt.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy Over Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da069f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_history_lt = CNNmodel.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=15,\n",
    "    validation_data=(x_test, y_test) # for val accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ee33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(CNN_history_lt.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "if \"val_accuracy\" in CNN_history_lt.history:\n",
    "    plt.plot(CNN_history_lt.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy Over Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3c5bd",
   "metadata": {},
   "source": [
    "Extra visualizations on how the machine identifies the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad15a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_test[0] # first image from test set\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73db7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(CNNmodel.predict(img[np.newaxis, ...]))\n",
    "print(f\"Predicted class: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ecbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(CNNmodel.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# i had problems showingcasing anything from my previous models due to some unknown errors, so i recreated the model here*\n",
    "#CNNmodel = keras.Sequential([\n",
    "#    keras.layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
    "#    keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "#    keras.layers.MaxPooling2D((2, 2)),\n",
    "#    keras.layers.Flatten(),\n",
    "#    keras.layers.Dense(10, activation=\"softmax\")\n",
    "#])\n",
    "\n",
    "inputs = tf.keras.Input(shape=(28, 28), name=\"input_layer\")\n",
    "x = tf.keras.layers.Reshape((28, 28, 1))(inputs)\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"valid\", name=\"conv1\")(x) # valid padding to be the same as the original one\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "functional_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "functional_model.set_weights(CNNmodel.get_weights())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd43063",
   "metadata": {},
   "source": [
    "* *Apparently sequential models cannot do this line \"activation_model = tf.keras.Model(inputs=functional_model.input, outputs=layer_outputs)\"\n",
    "because the tensors are \"skipped\" when they are made in sequential models but when they are explicity made with tensors as i did now they work well\n",
    "\n",
    "After some consideration i decided to not commit my tries because whatever I tried it simply didn\"t work so I just gave up with trying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f889dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_digit = 6\n",
    "indices = np.where(y_train == target_digit)[0] # get the first digit for whatever digit i want\n",
    "img = x_train[indices[0]]\n",
    "\n",
    "layer_outputs = [functional_model.get_layer(\"conv1\").output]\n",
    "activation_model = tf.keras.Model(inputs=functional_model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(img[np.newaxis, ...], verbose=0)[0]\n",
    "\n",
    "activity_per_filter = np.sum(activations, axis=(0, 1)) #activity is all the pixel values summed up\n",
    "\n",
    "top_indices = np.argsort(activity_per_filter)[::-1][:10] # top 10 most used filters\n",
    "\n",
    "print(f\"10 most active filters: {top_indices}\")\n",
    "print(f\"Activity values: {activity_per_filter[top_indices]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b3e8d",
   "metadata": {},
   "source": [
    "Let\"s see visually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 10, figsize=(15, 8))\n",
    "for plot_idx, filter_idx in enumerate(top_indices):\n",
    "    ax = axes[plot_idx]\n",
    "    feature_map = activations[:, :, filter_idx]\n",
    "    \n",
    "    # only get those that are actually used + normalize them\n",
    "    if feature_map.max() > 0:\n",
    "        feature_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())\n",
    "    \n",
    "    ax.imshow(feature_map, cmap=\"gray\")\n",
    "    ax.set_title(f\"Filter {filter_idx}\\nActivity: {activity_per_filter[filter_idx]:.2f}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Top Active Feature Maps (Digit {target_digit})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af39079",
   "metadata": {},
   "source": [
    "Since all of them look the same lets see if the kernels that go through them are also the same or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d176c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = CNNmodel.layers[1].get_weights()[0] # get all weights from the first Conv2D layer\n",
    "\n",
    "fig, axes = plt.subplots(1, 10, figsize=(12, 4))\n",
    "for i, idx in enumerate(top_indices):\n",
    "    ax = axes[i]\n",
    "    # get the specific 3x3 kernel for this filter\n",
    "    kernel = weights[:, :, 0, idx]\n",
    "    kernel_norm = (kernel - kernel.min()) / (kernel.max() - kernel.min())\n",
    "    \n",
    "    ax.imshow(kernel_norm, cmap=\"gray\")\n",
    "    ax.set_title(f\"Filter {idx}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"The difference between kernels and active feature maps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8e665",
   "metadata": {},
   "source": [
    "fashion MNIST with the same models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c60331",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fx_train, fy_train), (fx_test, fy_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(fx_train.shape)  # (60000, 28, 28)\n",
    "print(fy_train.shape)  # (60000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86105d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fx_train[0], cmap=\"gray\") # cmap=\"gray\" to make it balck & white\n",
    "plt.title(f\"Label: {fy_train[0]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_history_f = base_model.fit(\n",
    "    fx_train, fy_train,\n",
    "    epochs=20,\n",
    "    validation_data=(fx_test, fy_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb1b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(base_history_f.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "if \"val_accuracy\" in base_history_f.history:\n",
    "    plt.plot(base_history_f.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy Over Epochs (Fashion, Base)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac03786",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_history_f = CNNmodel.fit(\n",
    "    fx_train, fy_train,\n",
    "    epochs=20,\n",
    "    validation_data=(fx_test, fy_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f375db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(CNN_history_f.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "if \"val_accuracy\" in CNN_history_f.history:\n",
    "    plt.plot(CNN_history_f.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy Over Epochs (Fashion, CNN)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c3d572",
   "metadata": {},
   "source": [
    "pretty good basic scores, but fluctuates a lot which is expected due to varience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5f595",
   "metadata": {},
   "source": [
    "Next i will look at what are some ambiguous (?) pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = base_model.predict(fx_test)\n",
    "conf = np.max(probs, axis=1)\n",
    "pred_labels = np.argmax(probs, axis=1)\n",
    "ambi = np.where(conf < 0.8)[0]\n",
    "print(f\"Ambiguous samples: {len(ambi)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce00fb8",
   "metadata": {},
   "source": [
    "These are the classes and the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Heels\", \"Shirt\", \"Sneaker\", \"Bag\", \"boot\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for label in range(10):\n",
    "    # First index with this label\n",
    "    idx = np.where(fy_train == label)[0][0]\n",
    "    row, col = divmod(label, 5)\n",
    "    axes[row, col].imshow(fx_train[idx], cmap=\"gray\")\n",
    "    axes[row, col].set_title(f\"{label}: {class_names[label]}\")\n",
    "    axes[row, col].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "ambi = np.sort(ambi)\n",
    "for i, idx in enumerate(ambi[:10]):\n",
    "    row, col = divmod(i, 5)\n",
    "    axes[row, col].imshow(fx_test[idx].squeeze(), cmap=\"gray\")\n",
    "    top_prob = np.max(probs[idx])\n",
    "    top_class = class_names[pred_labels[idx]]\n",
    "    axes[row, col].set_title(f\"Pred: {top_class}, Conf: {top_prob:.2f}\")\n",
    "    axes[row, col].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14ddfb",
   "metadata": {},
   "source": [
    "### Extra section for the live coding task\n",
    "Should be 10 lines of code, will probably make some pretty graphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
